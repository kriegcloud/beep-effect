# =============================================================================
# @core-v2 Environment Configuration
# =============================================================================
#
# This is the canonical reference for all environment variables.
# Copy to .env for local development or .env.test for testing.
#
# IMPORTANT: This service uses Effect Config with nested prefixes.
# Variables are named: {PREFIX}_{FIELD} (e.g., LLM_API_KEY, STORAGE_TYPE)
#
# Environment File Strategy:
# - .env.example     - This file. Template with all variables documented
# - .env             - Local development (gitignored, copy from .env.example)
# - .env.test        - Test environment (tracked, used by test scripts)
# - .env.local       - DO NOT USE (removed, use .env instead)

# =============================================================================
# LLM Configuration (nested under LLM_ prefix)
# =============================================================================

# REQUIRED: API key for your chosen provider
# For Anthropic: Get from https://console.anthropic.com/settings/keys
# For OpenAI: Get from https://platform.openai.com/api-keys
# For Google: Get from https://ai.google.dev/
LLM_API_KEY=sk-ant-api03-your-key-here

# Provider: anthropic | openai | google
# Default: anthropic
LLM_PROVIDER=anthropic

# Model name - depends on provider
# Anthropic: claude-haiku-4-5, claude-sonnet-4-5, claude-opus-4-5
# OpenAI: gpt-4o, gpt-4o-mini, etc.
# Google: gemini-2.0-flash, gemini-1.5-pro, etc.
# Default: claude-haiku-4-5
LLM_MODEL=claude-haiku-4-5

# Request timeout in milliseconds
# Default: 60000 (60 seconds)
LLM_TIMEOUT_MS=60000

# Max output tokens per request
# Default: 4096
LLM_MAX_TOKENS=4096

# Temperature 0.0-1.0 (lower = more deterministic)
# Default: 0.1
LLM_TEMPERATURE=0.1

# =============================================================================
# Storage Configuration (nested under STORAGE_ prefix)
# =============================================================================

# Storage type: local | gcs | memory
# - local: File system storage (uses STORAGE_LOCAL_PATH)
# - gcs: Google Cloud Storage (uses STORAGE_BUCKET)
# - memory: In-memory only (for testing, data lost on restart)
# Default: local
STORAGE_TYPE=local

# Local file system path (used when STORAGE_TYPE=local)
# Can be relative or absolute. Created if doesn't exist.
# Default: none (required when STORAGE_TYPE=local)
# Development: /tmp/effect-ontology-dev
# Testing: /tmp/effect-ontology-test
STORAGE_LOCAL_PATH=/tmp/effect-ontology-dev

# GCS bucket name (required when STORAGE_TYPE=gcs)
# Example: my-project-ontology-storage
# Default: none
# STORAGE_BUCKET=my-bucket

# Path prefix for all storage keys (optional)
# Useful for multi-tenant deployments or namespacing
# Default: "" (no prefix)
# STORAGE_PREFIX=tenant-a/

# =============================================================================
# Ontology Configuration (nested under ONTOLOGY_ prefix)
# =============================================================================

# REQUIRED: Path to ontology file (TTL/RDF format)
#
# IMPORTANT: Must be an absolute path for local file-system OntologyService.
# Relative paths like "ontologies/football/ontology.ttl" fail because they are
# resolved from the current working directory (CWD), not the package root.
# This causes errors when the server is started from different directories.
#
# For local development with file-system backend:
#   Use absolute path: /absolute/path/to/ontology.ttl
#   Example: /Users/yourname/Dev/effect-ontology/ontologies/football/ontology.ttl
#
# For GCS backend (when STORAGE_TYPE=gcs):
#   Path can be relative or GCS URI format
#
# Default: none (required)
ONTOLOGY_PATH=/Users/pooks/Dev/effect-ontology/ontologies/football/ontology.ttl

# Cache TTL in seconds
# How long to cache parsed ontology in memory
# Default: 3600 (1 hour)
ONTOLOGY_CACHE_TTL=3600

# =============================================================================
# Runtime Configuration (nested under RUNTIME_ prefix)
# =============================================================================

# General concurrency limit
# Max parallel operations across the application
# Default: 4
RUNTIME_CONCURRENCY=4

# LLM-specific concurrency limit
# Max parallel LLM API calls (keep low to avoid rate limits)
# Default: 2
RUNTIME_LLM_CONCURRENCY=2

# Retry settings for API calls
# Default: 3 attempts
RUNTIME_RETRY_MAX=3

# Initial retry delay in milliseconds
# Default: 1000 (1 second)
RUNTIME_RETRY_INITIAL_DELAY=1000

# Maximum retry delay in milliseconds (with exponential backoff)
# Default: 30000 (30 seconds)
RUNTIME_RETRY_MAX_DELAY=30000

# Enable OpenTelemetry tracing
# Requires OTEL collector configured
# Default: false
RUNTIME_ENABLE_TRACING=false

# =============================================================================
# Grounder Configuration (nested under GROUNDER_ prefix)
# =============================================================================

# Enable relation grounding (ontology-based validation)
# When true, validates extracted relations against ontology
# Default: true
GROUNDER_ENABLED=true

# Minimum confidence threshold (0.0-1.0)
# Relations below this confidence are rejected
# Default: 0.8
GROUNDER_THRESHOLD=0.8

# Batch size for grouped verification
# How many relations to verify in a single LLM call
# Default: 5
GROUNDER_BATCH_SIZE=5

# =============================================================================
# RDF Configuration (nested under RDF_ prefix)
# =============================================================================

# Base namespace for generated RDF URIs
# Default: http://example.org/kg/
RDF_BASE_NAMESPACE=http://example.org/kg/

# Output format: Turtle | N-Triples | JSON-LD
# Default: Turtle
RDF_OUTPUT_FORMAT=Turtle

# =============================================================================
# Server Configuration
# =============================================================================

# HTTP server port
# Default: 8080
PORT=8080

# Node environment: development | test | production
# Affects logging, error handling, etc.
# Default: development
NODE_ENV=development

# =============================================================================
# PostgreSQL Configuration (optional - enables durable workflows)
# =============================================================================
# When configured, enables persistent workflow state via @effect/sql-pg
# Otherwise, workflows run in-memory only

# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DATABASE=workflow
# POSTGRES_USER=workflow
# POSTGRES_PASSWORD=secret

# =============================================================================
# Development Notes
# =============================================================================
#
# Bun Environment File Loading:
# - Auto-loads .env from working directory
# - Use --env-file to specify alternate file: bun --env-file=.env.test run server.js
# - Shell-sourced variables are overridden by bun's auto-loaded .env
#
# Test Scripts:
# - scripts/test-server.sh uses --env-file=.env.test
# - scripts/test-extract.sh sources .env.test for paths only
#
# Package.json Scripts:
# - "serve" uses default .env (for development)
# - Test scripts should use bun --env-file=.env.test
#
# Getting API Keys:
# - Check monorepo .env for VITE_LLM_ANTHROPIC_API_KEY
# - Or set directly in your local .env file
