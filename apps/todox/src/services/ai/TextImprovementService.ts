/**
 * TextImprovementService - AI-powered text improvement using Effect.
 *
 * Provides text improvement and transformation capabilities using @effect/ai
 * LanguageModel for LLM inference.
 *
 * @module todox/services/ai/TextImprovementService
 */

import { AiError, LanguageModel, Prompt } from "@effect/ai";
import * as Effect from "effect/Effect";
import * as Match from "effect/Match";
import * as Stream from "effect/Stream";
import { type AiErrorCode, TextImprovementError } from "./errors";

const SYSTEM_PROMPT = `You are a professional writing assistant. Your task is to improve or transform the given text according to the user's instruction.

IMPORTANT:
- Return ONLY the improved/transformed text
- Do NOT include explanations, comments, or meta-text
- Do NOT wrap the text in quotes or code blocks
- Preserve the original formatting style unless the instruction specifically asks to change it`;

const mapUnknownError = (error: unknown): TextImprovementError =>
  AiError.isAiError(error)
    ? mapAiError(error)
    : new TextImprovementError({
        code: "UNKNOWN",
        message: String(error),
        cause: "UnknownError",
      });

const mapErrorCode = (error: AiError.AiError): AiErrorCode =>
  Match.value(error._tag).pipe(
    Match.when("HttpRequestError", () => "NETWORK_ERROR" as const),
    Match.when("HttpResponseError", () => {
      const response = (error as AiError.HttpResponseError).response;
      const status = response.status;
      if (status === 401 || status === 403) return "API_KEY_INVALID" as const;
      if (status === 429) return "RATE_LIMIT" as const;
      if (status === 404) return "MODEL_UNAVAILABLE" as const;
      return "UNKNOWN" as const;
    }),
    Match.orElse(() => "UNKNOWN" as const)
  );

const mapAiError = (error: AiError.AiError): TextImprovementError =>
  new TextImprovementError({
    code: mapErrorCode(error),
    message: error.message,
    cause: error._tag,
  });

const buildUserContent = (text: string, instruction: string): string =>
  `Instruction: ${instruction}\n\nText to improve:\n${text}`;

/**
 * TextImprovementService - AI-powered text improvement
 *
 * Uses @effect/ai LanguageModel for text generation with structured
 * error handling and observability.
 *
 * @example
 * ```ts
 * import { TextImprovementService } from "@todox/services/ai";
 * import * as Effect from "effect/Effect";
 *
 * const program = Effect.gen(function* () {
 *   const service = yield* TextImprovementService;
 *   const improved = yield* service.improveText(
 *     "This is some text with errors.",
 *     "Fix grammar and spelling"
 *   );
 *   console.log(improved);
 * });
 * ```
 *
 * @category services
 */
export class TextImprovementService extends Effect.Service<TextImprovementService>()("@todox/TextImprovementService", {
  accessors: true,
  effect: Effect.gen(function* () {
    const model = yield* LanguageModel.LanguageModel;

    return {
      /**
       * Improve or transform text according to an instruction.
       *
       * @param text - The text to improve
       * @param instruction - The improvement instruction
       * @returns The improved text
       */
      improveText: Effect.fnUntraced(function* (text: string, instruction: string) {
        yield* Effect.logDebug("TextImprovementService.improveText: starting", {
          textLength: text.length,
          instructionLength: instruction.length,
        });

        const userContent = buildUserContent(text, instruction);

        const prompt = Prompt.make([
          { role: "system" as const, content: SYSTEM_PROMPT },
          { role: "user" as const, content: userContent },
        ]);

        const result = yield* model.generateText({ prompt }).pipe(Effect.mapError(mapAiError));

        yield* Effect.logDebug("TextImprovementService.improveText: complete", {
          inputLength: text.length,
          outputLength: result.text.length,
          inputTokens: result.usage.inputTokens,
          outputTokens: result.usage.outputTokens,
        });

        return result.text;
      }),

      /**
       * Stream improved text according to an instruction.
       *
       * Returns a Stream of text deltas as they are generated by the model.
       * Useful for progressive UI updates during text generation.
       *
       * @param text - The text to improve
       * @param instruction - The improvement instruction
       * @returns A stream of text deltas
       */
      improveTextStream: (text: string, instruction: string): Stream.Stream<string, TextImprovementError> => {
        const prompt = Prompt.make([
          { role: "system" as const, content: SYSTEM_PROMPT },
          { role: "user" as const, content: buildUserContent(text, instruction) },
        ]);

        return model.streamText({ prompt }).pipe(
          Stream.mapError(mapAiError),
          Stream.tap(() => Effect.logDebug("TextImprovementService.improveTextStream: received part")),
          Stream.mapEffect((part) =>
            Match.value(part).pipe(
              Match.discriminator("type")("text-delta", ({ delta }) => Effect.succeed(delta)),
              Match.discriminator("type")("error", ({ error }) => Effect.fail(mapUnknownError(error))),
              Match.orElse(() => Effect.succeed(""))
            )
          ),
          Stream.filter((s) => s.length > 0)
        );
      },
    };
  }),
}) {}
